<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>k8s on Wonyoung&#39;s Tech Blog</title>
    <link>https://wonyoungseo.github.io/tags/k8s/</link>
    <description>Recent content in k8s on Wonyoung&#39;s Tech Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© Wonyoung Seo 2023</copyright>
    <lastBuildDate>Sat, 23 Mar 2024 21:28:01 +0900</lastBuildDate><atom:link href="https://wonyoungseo.github.io/tags/k8s/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[KR] Kubernetes - Job / CronJob</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-23-k8s-job/</link>
      <pubDate>Sat, 23 Mar 2024 21:28:01 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-23-k8s-job/</guid>
      <description>Job  단발성으로 연산, 데이터 처리 등을 이유로 자원을 써야하는 경우도 있음 이러한 작업을 Pod로 구현한다면, Pod는 중료 후 재생성 되는 사이클을 반복함  restartPolicy: Always가 디폴트이기 때문에 사용자가 삭제하지 않는 한 Pod 는 실행 상태를 유지하는 것이 K8s 의 특성 restartPolicy: Never 로 설정하면 한번 실행하고 종료가 되긴 함.    만일 다수의 파드를 생성하고 배치로 스케쥴링 및 관리하고 싶다면 Job 오브젝트를 사용하면 됨. 싶다면?
Job 정의 apiVersion: batch/v1  # 버전 주의 kind: Job metadata: name: my-job spec: template: spec: cotainers: - name: math-add image: ubuntu command: [&amp;#39;expr&amp;#39;, &amp;#39;3&amp;#39;, &amp;#39;+&amp;#39;, &amp;#39;2&amp;#39;] restartPolicy: Never completions: 3 parallelism: 3   completion</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Readiness &amp; Liveness Probes</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-20-k8s-readiness-liveness-probes/</link>
      <pubDate>Wed, 20 Mar 2024 16:33:33 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-20-k8s-readiness-liveness-probes/</guid>
      <description>Status와 Conditions 쿠버네티스에서 Pod Status와 Conditions 은 파드의 상태를 확인하는 가장 기본적인 방법이다.
&amp;amp;nbsp
Pod Status
 kubectl get pods 상태 예시  Pending - 스케줄러가 파드를 스케줄링할 노드를 찾지 못 하면 ContainerCreating - 스케줄링되면, 이미지를 받아 컨테이너를 실행하는 상태 Running - 실행 중       &amp;amp;nbsp
Pod Condition
 kubectl describe pods Pod Status 에 비해 더 세부적인 현상태를 조회할 수 있음. 4가지 상태 카테고리를 True/False 로 나타냄.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Monitoring &amp; Logging</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-20-k8s-logging-monitoring/</link>
      <pubDate>Wed, 20 Mar 2024 15:07:09 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-20-k8s-logging-monitoring/</guid>
      <description>CKAD 를 준비하는 선에서 과정에서 정리한 내용으로, 실제로 쿠버네티스에서 로깅과 모니터링과 관련된 내용은 훨씬 더 방대할 수 있습니다.
 Monitoring  쿠버네티스의 클러스터를 모니터링하고자 한다면, 주로 다음과 같은 데이터를 보고자 함일 것이다.  Node 별 리소스 사용 현황 Node 별 Pod의 갯수 Pod 별 리소스 사용 현황 etc &amp;hellip;   쿠버네티스는 빌트인 모니터링 기능을 제공하고 있지 않지만, 여러가지 툴이 존재함.  Metrics Server Prometheus Elastic Stack Data Dog dynatrace etc &amp;hellip;    Metrics Server (모니터링 툴 예시)  하나의 클러스터를 기준으로 작동함.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Node Selector &amp; Node Affinity</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-18-k8s-node-affinity/</link>
      <pubDate>Mon, 18 Mar 2024 11:09:22 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-18-k8s-node-affinity/</guid>
      <description>Node Selector와 Node Affinity는 Pod에 제한을 걸어 특정 노드에만 스케줄링 될 수 있도록 하는 설정임
예시)
 만일 클러스터 중에 하나의 노드에 GPU가 장착이 되어 있다면 딥러닝 훈련 Pod는 해당 노드에 스케줄링되어 구동되도록 함  NodeSelector  간단하고, 가볍게 하나의 Pod에 적용시킬 수 있는 설정    Node에 레이블 적용하기
 kubectl label nodes &amp;lt;node-name&amp;gt; &amp;lt;label-key&amp;gt;=&amp;lt;label-value&amp;gt; 예시) kubectl label nodes node01 size=Large    Pod에도 &amp;lt;label-value&amp;gt; 명시하기. Node에 적용된 Label 과 매칭되어 스케줄링 됨.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Taints &amp; Tolerance</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-17-k8s-taints-tolerance/</link>
      <pubDate>Sun, 17 Mar 2024 18:11:07 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-17-k8s-taints-tolerance/</guid>
      <description>Taints and Tolerance  특정 노드에 파드의 무작위 스케줄링을 제한하고, 특정 유형의 파드의 스케줄링만 허용할 때 사용되는 설정 노드를 taint (오염) 시켜서 파드가 접근하지 못 하게 한 후, 노드에 적용된 taint에 대한 tolerance(내성) 을 가진 파드만 스케줄링 된다는 개념  Node에 Taint 적용하기 kubectl taint nodes &amp;lt;node-name&amp;gt; &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt;:&amp;lt;taint-effect&amp;gt; 예시)
# node1에 taint 적용 kubectl taint nodes node1 app=blue:NoSchedule # taint 제거 kubectl taint nodes node1 app=blue:NoSchedule- taint-effect 의 유형  NoSchedule - 포드가 스케쥴되지 않음 PreferNoSchedule - 해당 노드는 피하지만 보장된 것은 아님 NoExecute - 파드가 스케쥴되지 않으며, 현재 존재하는 파드도 tolerant가 없다면 제외함.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Resource Requirements</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-16-k8s-resource-requirements/</link>
      <pubDate>Sat, 16 Mar 2024 14:17:03 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-16-k8s-resource-requirements/</guid>
      <description>쿠버네티스 상에서의 자원 할당 쿠버네티스에서 Pod가 구동되기 위해서는 스케줄링 된 노드 내 가용할 수 있는 리소스를 사용한다.
 kube-schduler 는 Pod가 필요로 하는 자원을 어느 노드에서 구동시킬 지 결정함. 만일 모든 노드에서 Pod를 구동시킬 수 있는 자원이 충분히 남아있지 않을 경우  스케줄러는 Pod를 할당하지 않고 스케줄링을 멈춤. Pod를 Pending State 이 됨.  STATUS=pending 표기가 되며, Event 에도 Insufficient resource로 표기됨      Resource Requirements  Resource Requirements 는 Pod를 구동시키기 위해 필요한 최소 자원을 명시하는 것.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - SecurityContext</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-14-securitycontext/</link>
      <pubDate>Thu, 14 Mar 2024 21:18:33 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-14-securitycontext/</guid>
      <description>K8s에서의 컨테이너 보안 기능 도커에서는 Namespace를 통해 user (User Namespace), file system (Mount Namespace) 등을 분리하고, Capabilities 에서 선택적인 권한을 부여하는 등 보안 기능이 있는데, 쿠버네티스에서도 Security Context를 통해 동일하게 적용이 가능하다.
 쿠버네티스에서 컨테이너는 Pod로 캡슐화 되므로, 위의 보안 적용은 컨테이너 레벨 또는 Pod 레벨 모두 적용 가능함. Pod 레벨에서 적용할 경우, Pod 내 모든 컨테이너에 동일하게 적용됨. 만일 서로 다른 설정을 컨테이너와 Pod에 설정하면, 컨테이너 설정이 Pod를 오버라이드 함.</description>
    </item>
    
    <item>
      <title>Kubernetes - Command / Args / Configmap / Secret</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-12-k8s-configmap-secret/</link>
      <pubDate>Tue, 12 Mar 2024 12:32:08 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-12-k8s-configmap-secret/</guid>
      <description>Command &amp;amp; Arguments Docker Image를 기반으로 Pod 를 생성하면서 command 와 argument를 주입하려는 경우
  예시 Docker Image
# 예시 DockerfileFROMubuntuENTRYPOINT [&amp;#34;sleep&amp;#34;]CMD [&amp;#34;5&amp;#34;]  Pod definition 파일에서 CMD 오버라이드 하기
apiVersion: v1 kind: Pod metadata: name: ubuntu-sleep-pod spec: containers: - name: ubuntu-sleep-pod image: ubuntu-sleep-pod args: [&amp;#34;10&amp;#34;] ## &amp;lt;--- CMD override   Pod definition 파일에서 ENTRYPOINT 오버라이드 하기
apiVersion: v1 kind: Pod metadata: name: ubuntu-sleeper-pod spec: containers: - name: ubuntu-sleeper-pod image: ubuntu-sleeper-pod command: [&amp;#34;echo&amp;#34;] # &amp;lt;--- ENTRYPOINT override args: [&amp;#34;10&amp;#34;] # &amp;lt;--- CMD override   Environment Variables 환경변수 K8s Pod을 생성하는 과정에서 환경 변수 타입은 크게 3가지가 있음</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Multi-Container Pod</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-08-k8s-multiple-container-pod/</link>
      <pubDate>Fri, 08 Mar 2024 01:44:13 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-08-k8s-multiple-container-pod/</guid>
      <description>Multi-Container Pod  (처음 쿠버네티스와 Pod의 개념에 대해 설명할 때) 파드는 최소의 배포단위이기에 여러 개의 어플리케이션 컨테이너를 묶어 하나의 파드로 배포하는 것은 적절한 사용법이 아님. 그러나, 하나의 파드에 복수의 컨테이너를 함께 구성하여 배포하는 방식이 충분히 고려될 수 있음.  다른 컨테이너를 통해 실행되는 서비스가 메인 어플리케이션을 보조하는 경우 동일 스토리지 또는 네트워크의 공유하는 서비스가 필요한 경우 동일한 라이프사이클을 이루는 경우  생성, 배포, 삭제, 스케일 업다운이 동일하게 적용되어야 하는 경우.   예) 웹서버와 별도로 로깅 서비스가 함께 페어를 이룬 경우   따라서 굳이 별도의 파드에 분리할 필요가 없음.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - NameSpace</title>
      <link>https://wonyoungseo.github.io/posts/2024-03-05-k8s-namespace/</link>
      <pubDate>Tue, 05 Mar 2024 01:44:13 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-03-05-k8s-namespace/</guid>
      <description>Namespace  Namespace 는 쿠버네티스 내 존재하는 가상의 공간 클러스터 내에서 오브젝트들과 리소스 그룹을 &amp;ldquo;논리적&amp;quot;으로 분리함. (물리적 분리가 아님) 작은 규모의 클러스터에서는 그냥 default에서 작업하면 되지만, 엔터프라이즈나 프로덕션 환경에서는 Namespace를 사용하는 것이 좋음  적용 예시  사용자에 따라 Namespace 접근 권한을 다르게 부여할 수 있음. Namespace마다 다른 정책을 부여할 수 있음. Namespace 별로 리소스 할당량(resource quota)을 지정/정의할 수 있음  Namespace의 유형 Default Namespace  Cluster가 처음 생성될 때 K8s가 default로 생성함 프로덕션 클러스터의 경우 Default Namespace를 사용하지 않고, 다른 Namespace를 만드는 것이 권장됨.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - PV &amp; PVC</title>
      <link>https://wonyoungseo.github.io/posts/2024-02-29-k8s-pv-pvc/</link>
      <pubDate>Thu, 29 Feb 2024 03:18:50 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-02-29-k8s-pv-pvc/</guid>
      <description>K8s PV / PVC 기본 개념 데이터를 영구적으로 저장하는 매커니즘 Persistent Storage
1. 주요 개념 PV (Persistent Volume)  K8s Object 클러스터의 스토리지역할을 하는 클러스터 리소스의 일종 관리자가 프로비저닝하거나 Storage Class를 통해 동적으로 프로비저닝 됨 일반 볼륨과의 차이점  일반 볼륨은 Pod와 같은 라이프사이클을 가짐. 함께 생성되고 함께 내려간다는 뜻 PV는 Pod와 별개의 라이프사이클을 가지므로, Pod가 종료되어도 PV에 기록된 데이터는 삭제되지 않음    PVC (Persistent Volume Claim)  K8s Object PVC는 PV 라는 리소스에 대한 요청 + 리소스에 대한 클레임 검사 역할 PVC를 명시하면 쿠버네티스는 적정한 크기와 접근 모드의 PV를 찾고 PVC를 PV에 할당함.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Network, Service</title>
      <link>https://wonyoungseo.github.io/posts/2024-01-25-k8s-trial-network-service/</link>
      <pubDate>Thu, 25 Jan 2024 14:17:49 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-01-25-k8s-trial-network-service/</guid>
      <description>Network Single Node 상황  쿠버네티스에서는 내부 IP 주소가 Pod에 할당됨. 쿠버네티스 클러스터는 처음 설정될 때, internal private network 를 생성함  모든 pods는 이 네트워크의 레인지 내에서 IP를 부여받음   Pod가 재생성될 때는 또 새로운 IP를 부여받음  따라서, Pod에 부여된 IP로 접근하는 것은 적절한 방법이 아님    Multiple Nodes in a Cluster 상황  각 Node 의 IP는 다르지만, 각 노드 내 Pod의 네트워크가 같을 수 있음 하지만,  모든 Container / Pod는 NAT 없이도 서로 networking 가능 모든 Node는 NAT 없이도 서로 networking 가능   따라서 IP conflict 을 피하기 위한 조치가 필요함 pre-built solution 존재하기도 함  cisco big cloud fabric flannel vmware nsx calico cilium … etc     Service   helps connecting applications together with other applications OR userss ex)  backend server frontend application external datasource etc …    Service 개념  Service는 Kubernetes를 기반으로 하는 어플리케이션 내외의 통신과 접근을 위한 obejct Service 유형  Node Port service  node의 port 에서부터 listen(응답대기) → request 를 pod로 전달하는 역할   Cluster IP  클러스터 내 virtual IP를 생성하여 제각기 다른 service들 간의 통신을 가능케 함.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - Pod / ReplicaSet / Deployment</title>
      <link>https://wonyoungseo.github.io/posts/2024-01-18-k8s-trial-pod-replica-deployment/</link>
      <pubDate>Thu, 18 Jan 2024 15:12:01 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-01-18-k8s-trial-pod-replica-deployment/</guid>
      <description>Pod 쿠버네티스에서 Pod를 정의하는 정의하는 yaml의 형태는 다음과 같다.
(Pod 뿐만 아니라 다른 오브젝트도 동일)
# pod-definition.yml apiVersion: kind: metadata: spec: containers: - name: # - before the name indicates, its first item in the list image: Pod 관련 명령어
kubectl create -f [FILE NAME].yml
kubectl create -f [FILE NAME].yml --record 또는 kubectl apply -f [FILE NAME].yml
kubectl get pods
kubectl describe pod [POD NAME]
Labels, Selectors 개념  Labels and Selectors act as a filter, filtering pods for ReplicsSet Labels와 Selectors는 필터로서의 기능을 함.</description>
    </item>
    
    <item>
      <title>[KR] Kubernetes - 개념 정리</title>
      <link>https://wonyoungseo.github.io/posts/2024-01-15-k8s-concept/</link>
      <pubDate>Mon, 15 Jan 2024 21:33:01 +0900</pubDate>
      
      <guid>https://wonyoungseo.github.io/posts/2024-01-15-k8s-concept/</guid>
      <description>1 쿠버네티스 개념 아키텍처 1.1. 개념  컨테이너화 된 어플리케이션의 배포, 확장, 운영을 자동화하기 위한 오픈소스 시스템 구글에 의해 개발됨. CNCF에 기반을 둠  1.2. 주요 특징  자동화된 롤아웃 및 롤백  어플리케이션 업데이트 시 롤아웃을 자동으로 관리 문제 발생 시 이전 버전으로 롤백   서비스 접근 및 로드 밸런싱  클러스터 내의 어플리케이션에 쉬벡 접근 트래픽을 자동으로 분산   스케일링  리소스의 사용에 따라 자동 또는 수동으로 스케일링   자체 회복  실패한 컨테이너 재시작.</description>
    </item>
    
  </channel>
</rss>
