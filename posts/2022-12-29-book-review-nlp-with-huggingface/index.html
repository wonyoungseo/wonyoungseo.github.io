<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[KR] 책 리뷰 : 트랜스포머를 활용한 자연어처리 | Wonyoung's Tech Blog</title><meta name=keywords content="트랜스포머를활용한자연어처리 ,한빛미디어 나는 리뷰어다 2022"><meta name=description content="트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)
  추천하는 대상:
 파이썬과 딥러닝 프레임워크에 익숙한 리서처 & 엔지니어 자연어처리 프로젝트를 진행하는 모든 분 !  Transformer와 Huggingface 어텐션(Attention) 메커니즘의 등장은 트랜스포머(Transformer) 모델 구조로 이어지며 최근 몇년 간 자연어처리 기술 발전의 근간이 되었다. 이와 더불어 허깅페이스(Huggingface)는 트랜스포머 그 자체로 동일한 이름을 가진 라이브러리가 등장시켰고, 모델에 대한 사용성과 접근성을 크게 개선했다.
트랜스포머를 활용한 자연어처리 는 허깅페이스에 대한 전반적인 소개와 사용법을 다룬다."><meta name=author content="Wonyoung Seo"><link rel=canonical href=https://wonyoungseo.github.io/posts/2022-12-29-book-review-nlp-with-huggingface/><meta name=google-site-verification content="XYZabc"><link href=/assets/css/stylesheet.min.d8cbf60331b9ced42909130bf88f8b97d2eb3de242444dcc9e2df410ceb098b9.css integrity="sha256-2Mv2AzG5ztQpCRML+I+Ll9LrPeJCRE3Mni30EM6wmLk=" rel="preload stylesheet" as=style><link rel=icon href=https://wonyoungseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://wonyoungseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://wonyoungseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://wonyoungseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://wonyoungseo.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><meta property="og:title" content="[KR] 책 리뷰 : 트랜스포머를 활용한 자연어처리"><meta property="og:description" content="트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)
  추천하는 대상:
 파이썬과 딥러닝 프레임워크에 익숙한 리서처 & 엔지니어 자연어처리 프로젝트를 진행하는 모든 분 !  Transformer와 Huggingface 어텐션(Attention) 메커니즘의 등장은 트랜스포머(Transformer) 모델 구조로 이어지며 최근 몇년 간 자연어처리 기술 발전의 근간이 되었다. 이와 더불어 허깅페이스(Huggingface)는 트랜스포머 그 자체로 동일한 이름을 가진 라이브러리가 등장시켰고, 모델에 대한 사용성과 접근성을 크게 개선했다.
트랜스포머를 활용한 자연어처리 는 허깅페이스에 대한 전반적인 소개와 사용법을 다룬다."><meta property="og:type" content="article"><meta property="og:url" content="https://wonyoungseo.github.io/posts/2022-12-29-book-review-nlp-with-huggingface/"><meta property="og:image" content="https://wonyoungseo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:published_time" content="2022-12-29T16:31:07+09:00"><meta property="article:modified_time" content="2022-12-29T16:31:07+09:00"><meta property="og:site_name" content="WY's Tech Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://wonyoungseo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[KR] 책 리뷰 : 트랜스포머를 활용한 자연어처리"><meta name=twitter:description content="트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)
  추천하는 대상:
 파이썬과 딥러닝 프레임워크에 익숙한 리서처 & 엔지니어 자연어처리 프로젝트를 진행하는 모든 분 !  Transformer와 Huggingface 어텐션(Attention) 메커니즘의 등장은 트랜스포머(Transformer) 모델 구조로 이어지며 최근 몇년 간 자연어처리 기술 발전의 근간이 되었다. 이와 더불어 허깅페이스(Huggingface)는 트랜스포머 그 자체로 동일한 이름을 가진 라이브러리가 등장시켰고, 모델에 대한 사용성과 접근성을 크게 개선했다.
트랜스포머를 활용한 자연어처리 는 허깅페이스에 대한 전반적인 소개와 사용법을 다룬다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[KR] 책 리뷰 : 트랜스포머를 활용한 자연어처리","name":"[KR] 책 리뷰 : 트랜스포머를 활용한 자연어처리","description":"트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)\n  추천하는 대상:\n 파이썬과 딥러닝 프레임워크에 익숙한 리서처 \u0026amp;amp; 엔지니어 자연어처리 프로젝트를 진행하는 모든 분 !  Transformer와 Huggingface 어텐션(Attention) 메커니즘의 등장은 트랜스포 …","keywords":["트랜스포머를활용한자연어처리 ","한빛미디어 나는 리뷰어다 2022"],"articleBody":"   트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)\n  추천하는 대상:\n 파이썬과 딥러닝 프레임워크에 익숙한 리서처 \u0026 엔지니어 자연어처리 프로젝트를 진행하는 모든 분 !  Transformer와 Huggingface 어텐션(Attention) 메커니즘의 등장은 트랜스포머(Transformer) 모델 구조로 이어지며 최근 몇년 간 자연어처리 기술 발전의 근간이 되었다. 이와 더불어 허깅페이스(Huggingface)는 트랜스포머 그 자체로 동일한 이름을 가진 라이브러리가 등장시켰고, 모델에 대한 사용성과 접근성을 크게 개선했다.\n트랜스포머를 활용한 자연어처리 는 허깅페이스에 대한 전반적인 소개와 사용법을 다룬다. 앞서 서술한 바와 같이 이 책은 파이썬 프로그래밍과 딥러닝 프레임워크에 익숙하며, 이미 NLP를 적용한 프로젝트에 익숙한 분들이 대상 독자로 적합하다.\n책의 구성 내용의 구성은 아래와 같다.\n 1 ~ 3장 : 트랜스포머와 허깅페이스 라이브러리, 생태계 소개  2장 : 분류 (Text Classification)   4 ~ 7장 : 허깅페이스를 활용한 자연어처리 태스크 별 적용 소개  4장 : 개체명인식 (Named Entity Recognition) 5장 : 생성 (Text Generation) 6장 : 요약 (Text Summarization) 7장 : 질의응답 (Question \u0026 Answering)   8장 ~ 10장 : 모델 성능 향상 11장 : 향후 로드맵  가장 핵심적인 장점 허깅페이스의 이름 아래 조성된 생태계는 초창기 트랜스포머 라이브러리와는 달리 매우 거대해졌다. NLP 뿐만 아니라 컴퓨터비전 문제를 해결하기 위한 모델도 허깅페이스를 통해 접할 수 있게 된 세상이다.\n어디서부터 시작해야할 지 막연할 수도 있지만 허깅페이스 소속 엔지니어와 오픈소스 프로젝트에 참여한 개발자가 직접 참여한 트랜스포머를 활용한 자연어처리 는 프로젝트를 시작하거나 어플리케이션을 개발하고자 하는 분께 허깅페이스의 무엇을 어떻게 활용할 지 훌륭한 가이드가 된다.\n 한빛미디어 활동을 위해서 책을 제공받아 작성된 서평입니다.\n","wordCount":"225","inLanguage":"en","datePublished":"2022-12-29T16:31:07+09:00","dateModified":"2022-12-29T16:31:07+09:00","author":{"@type":"Person","name":"Wonyoung Seo"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wonyoungseo.github.io/posts/2022-12-29-book-review-nlp-with-huggingface/"},"publisher":{"@type":"Organization","name":"Wonyoung's Tech Blog","logo":{"@type":"ImageObject","url":"https://wonyoungseo.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://wonyoungseo.github.io/ accesskey=h title="Tech Blog (Alt + H)">Tech Blog</a>
<span class=logo-switches><a id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://wonyoungseo.github.io/archives/ title=posts><span>posts</span></a></li><li><a href=https://wonyoungseo.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://wonyoungseo.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://wonyoungseo.github.io/about/ title=about><span>about</span></a></li><li><a href=https://wonyoungseo.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>[KR] 책 리뷰 : 트랜스포머를 활용한 자연어처리</h1><div class=post-meta>December 29, 2022&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Wonyoung Seo</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#transformer%ec%99%80-huggingface aria-label="Transformer와 Huggingface">Transformer와 Huggingface</a><ul><li><a href=#%ec%b1%85%ec%9d%98-%ea%b5%ac%ec%84%b1 aria-label="책의 구성">책의 구성</a></li><li><a href=#%ea%b0%80%ec%9e%a5-%ed%95%b5%ec%8b%ac%ec%a0%81%ec%9d%b8-%ec%9e%a5%ec%a0%90 aria-label="가장 핵심적인 장점">가장 핵심적인 장점</a></li></ul></li></ul></div></details></div><div class=post-content><figure><center><img src=/2022-12-29-book-review-nlp-with-huggingface/1.jpg alt="트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)"></center> <center><figcaption><p>트래스포머를 활용한 자연어처리 (저자: 루이스 턴스톨, 레안드로 폰 베라, 토마스 울프)</p></figcaption></center></figure><p>추천하는 대상:</p><ul><li>파이썬과 딥러닝 프레임워크에 익숙한 리서처 & 엔지니어</li><li>자연어처리 프로젝트를 진행하는 모든 분 !</li></ul><h1 id=transformer와-huggingface>Transformer와 Huggingface<a hidden class=anchor aria-hidden=true href=#transformer와-huggingface>#</a></h1><p>어텐션(Attention) 메커니즘의 등장은 트랜스포머(Transformer) 모델 구조로 이어지며 최근 몇년 간 자연어처리 기술 발전의 근간이 되었다. 이와 더불어 허깅페이스(Huggingface)는 트랜스포머 그 자체로 동일한 이름을 가진 라이브러리가 등장시켰고, 모델에 대한 사용성과 접근성을 크게 개선했다.</p><p><strong><em>트랜스포머를 활용한 자연어처리</em></strong> 는 허깅페이스에 대한 전반적인 소개와 사용법을 다룬다. 앞서 서술한 바와 같이 이 책은 파이썬 프로그래밍과 딥러닝 프레임워크에 익숙하며, 이미 NLP를 적용한 프로젝트에 익숙한 분들이 대상 독자로 적합하다.</p><h2 id=책의-구성>책의 구성<a hidden class=anchor aria-hidden=true href=#책의-구성>#</a></h2><p>내용의 구성은 아래와 같다.</p><ul><li>1 ~ 3장 : 트랜스포머와 허깅페이스 라이브러리, 생태계 소개<ul><li>2장 : 분류 (Text Classification)</li></ul></li><li>4 ~ 7장 : 허깅페이스를 활용한 자연어처리 태스크 별 적용 소개<ul><li>4장 : 개체명인식 (Named Entity Recognition)</li><li>5장 : 생성 (Text Generation)</li><li>6장 : 요약 (Text Summarization)</li><li>7장 : 질의응답 (Question & Answering)</li></ul></li><li>8장 ~ 10장 : 모델 성능 향상</li><li>11장 : 향후 로드맵</li></ul><h2 id=가장-핵심적인-장점>가장 핵심적인 장점<a hidden class=anchor aria-hidden=true href=#가장-핵심적인-장점>#</a></h2><p>허깅페이스의 이름 아래 조성된 생태계는 초창기 트랜스포머 라이브러리와는 달리 매우 거대해졌다. NLP 뿐만 아니라 컴퓨터비전 문제를 해결하기 위한 모델도 허깅페이스를 통해 접할 수 있게 된 세상이다.</p><p>어디서부터 시작해야할 지 막연할 수도 있지만 허깅페이스 소속 엔지니어와 오픈소스 프로젝트에 참여한 개발자가 직접 참여한 <strong><em>트랜스포머를 활용한 자연어처리</em></strong> 는 프로젝트를 시작하거나 어플리케이션을 개발하고자 하는 분께 허깅페이스의 무엇을 어떻게 활용할 지 훌륭한 가이드가 된다.</p><hr><p><em>한빛미디어 &lt;나는 리뷰어다> 활동을 위해서 책을 제공받아 작성된 서평입니다.</em></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://wonyoungseo.github.io/tags/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%EB%A5%BC%ED%99%9C%EC%9A%A9%ED%95%9C%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/>트랜스포머를활용한자연어처리</a></li><li><a href=https://wonyoungseo.github.io/tags/%ED%95%9C%EB%B9%9B%EB%AF%B8%EB%94%94%EC%96%B4-%EB%82%98%EB%8A%94-%EB%A6%AC%EB%B7%B0%EC%96%B4%EB%8B%A4-2022/>한빛미디어 나는 리뷰어다 2022</a></li></ul></footer></article></main><footer class=footer><span>© Wonyoung Seo 2023</span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>