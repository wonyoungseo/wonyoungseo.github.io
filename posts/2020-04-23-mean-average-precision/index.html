<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[KR] 추천시스템의 평가 지표 : MAP | WY Seo Blog</title><meta name=keywords content="recsys,map"><meta name=description content="추천 시스템의 평가 지표 &mldr; ? 추천 시스템은 이름에서도 알 수 있듯, 어떤 사용자가 관심을 가질 법한 아이템을 추천하는 알고리즘이다. 추천 시스템의 성능은 어떻게 평가할 수 있을까? 추천시스템에 대해 깊게 생각하지 않았을 적에는 분류 문제에서 성능을 평가하는 것과 비슷하다고 생각했다. &ldquo;사용자가 관심을 가질만한 아이템이 맞다 또는 아니다.&#34; 를 측정한다면, 우리에게 익숙한 precision, recall 등으로 생각해볼 수도 있을 것 같다.
하지만, 분류 성능 지표에서는 추천의 순서나 순위가 고려되지 않는다. (역시 어줍잖게 생각하면 안 돼 &mldr;)"><meta name=author content="Wyoung Seo"><link rel=canonical href=https://lucaseo.github.io/posts/2020-04-23-mean-average-precision/><meta name=google-site-verification content="XYZabc"><link href=/assets/css/stylesheet.min.d8cbf60331b9ced42909130bf88f8b97d2eb3de242444dcc9e2df410ceb098b9.css integrity="sha256-2Mv2AzG5ztQpCRML+I+Ll9LrPeJCRE3Mni30EM6wmLk=" rel="preload stylesheet" as=style><link rel=icon href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body);></script><meta property="og:title" content="[KR] 추천시스템의 평가 지표 : MAP"><meta property="og:description" content="추천 시스템의 평가 지표 &mldr; ? 추천 시스템은 이름에서도 알 수 있듯, 어떤 사용자가 관심을 가질 법한 아이템을 추천하는 알고리즘이다. 추천 시스템의 성능은 어떻게 평가할 수 있을까? 추천시스템에 대해 깊게 생각하지 않았을 적에는 분류 문제에서 성능을 평가하는 것과 비슷하다고 생각했다. &ldquo;사용자가 관심을 가질만한 아이템이 맞다 또는 아니다.&#34; 를 측정한다면, 우리에게 익숙한 precision, recall 등으로 생각해볼 수도 있을 것 같다.
하지만, 분류 성능 지표에서는 추천의 순서나 순위가 고려되지 않는다. (역시 어줍잖게 생각하면 안 돼 &mldr;)"><meta property="og:type" content="article"><meta property="og:url" content="https://lucaseo.github.io/posts/2020-04-23-mean-average-precision/"><meta property="og:image" content="https://lucaseo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:published_time" content="2020-04-23T14:24:01+09:00"><meta property="article:modified_time" content="2020-04-23T14:24:01+09:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://lucaseo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[KR] 추천시스템의 평가 지표 : MAP"><meta name=twitter:description content="추천 시스템의 평가 지표 &mldr; ? 추천 시스템은 이름에서도 알 수 있듯, 어떤 사용자가 관심을 가질 법한 아이템을 추천하는 알고리즘이다. 추천 시스템의 성능은 어떻게 평가할 수 있을까? 추천시스템에 대해 깊게 생각하지 않았을 적에는 분류 문제에서 성능을 평가하는 것과 비슷하다고 생각했다. &ldquo;사용자가 관심을 가질만한 아이템이 맞다 또는 아니다.&#34; 를 측정한다면, 우리에게 익숙한 precision, recall 등으로 생각해볼 수도 있을 것 같다.
하지만, 분류 성능 지표에서는 추천의 순서나 순위가 고려되지 않는다. (역시 어줍잖게 생각하면 안 돼 &mldr;)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[KR] 추천시스템의 평가 지표 : MAP","name":"[KR] 추천시스템의 평가 지표 : MAP","description":"추천 시스템의 평가 지표 \u0026amp;hellip; ? 추천 시스템은 이름에서도 알 수 있듯, 어떤 사용자가 관심을 가질 법한 아이템을 추천하는 알고리즘이다. 추천 시스템의 성능은 어떻게 평가할 수 있을까? 추천시스템에 대해 깊게 생각하지 않았을 적에는 분류 문제에서 성능을 평가하는 것과 비슷하다고 생각했다. \u0026amp;ldquo;사용자가  …","keywords":["recsys","map"],"articleBody":"추천 시스템의 평가 지표 … ? 추천 시스템은 이름에서도 알 수 있듯, 어떤 사용자가 관심을 가질 법한 아이템을 추천하는 알고리즘이다. 추천 시스템의 성능은 어떻게 평가할 수 있을까? 추천시스템에 대해 깊게 생각하지 않았을 적에는 분류 문제에서 성능을 평가하는 것과 비슷하다고 생각했다. “사용자가 관심을 가질만한 아이템이 맞다 또는 아니다.\" 를 측정한다면, 우리에게 익숙한 precision, recall 등으로 생각해볼 수도 있을 것 같다.\n하지만, 분류 성능 지표에서는 추천의 순서나 순위가 고려되지 않는다. (역시 어줍잖게 생각하면 안 돼 …)\n추천 시스템을 통해 추천되는 아이템의 경우 추천의 정도가 동일하지 않다. 대부분의 추천 결과는 다음처럼 나올 수 있다고 생각해 볼 수 있다.\n 1순위 : 가장 관심을 가질만한 것.\n2순위 : 그 다음 차선책으로 관심을 가질만한 것.\n3순위 : 그 다음으로 사용자가 관심을 가질만한 것.\n4순위 : 또 그 다음 … …\n \u0026nbsp\nMean Average Precision (MAP) 은 순서 또는 순위를 감안하는 부분을 반영하여 추천 시스템의 성능을 평가하는 지표로서, 과거 캐글의 Stander Product Recommendation, 카카오아레나의 브런치 사용자를 위한 글 추천 대회 등 추천 시스템 관련 컴퍼티션에서 채점 방식으로 적용되었다. 특히 분류 문제에서 흔히 언급되는 Precision과 Recall이 적용된 성능평가 방법으로, 아주 낯설지는 않다.\n\u0026nbsp\nPrecision \u0026 Recall     Predict Positive Predict Negative     Actual Positive True Positive False Negative   Actual Negetave False Positive True Negative    MAP에 대한 개념는 Precision과 Recall에서부터 시작한다. 일반적으로 위와과 같이 confusion matrix가 있다고 할 때, Precision과 Recall은 다음과 같다. (더 자세한 설명은 링크를 참조하도록 하자)\n$$\\text{Precision} = \\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}$$\n$$\\text{Recall} = \\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}$$\n\u0026nbsp\n추천시스템 관점에서의 Precision \u0026 Recall 추천시스템에서는 Precision과 Recall을 다음과 같이 해석할 수 있다. 추천시스템에서는 분자 부분을 relevant(관련있는) 라고 표현하기도 한다.\n     Precision 또는 \\(P\\):\n 추천한 아이템 중, 실제로 사용자의 관심사와 겹치는 아이템의 비율 \\(\\text{Precision} = \\frac{\\text{Items from recommendation that fit user’s interest}}{\\text{Total items from recommendation}}\\)    Recall 또는 \\(r\\):\n 실제로 사용자가 관심을 가진 아이템 중, 추천된 아이템이 겹치는 비율 \\(\\text{Recall} = \\frac{\\text{Items from recommendation that fit user’s interest}}{\\text{User’s interest}}\\)    \u0026nbsp\nCutoff (@K) MAP에서는 Cutoff의 개념이 등장한다. Cutoff는 “잘라낸다\"는 뜻으로, 쉽게 말하면 “상위 K개만 고려하고 그 아래로는 쳐내기” 라고 이해하면 된다. Cutoff를 가질 경우에는, @K 를 덧붙여서 표기한다.\n어떠한 사용자의 기록을 통해서 자동차 용품와 관련된 아이템을 추천한 결과가 다음과 같다고 하자.\n   순위 추천 아이템 정답 / 오답     1 엔진 오일 정답   2 자동차 배터리 정답   3 차량용 방향제 정답   4 자동차 장난감 오답   5 자동차 워셔액 정답   6 초보운전 스티커 오답   7 타이어 정답   8 운전자 보험 상품 오답   9 렌트카 이용권 오답   10 자동차 핸드폰 거치대 정답    다음 예시의 추천시스템의 결과에 대하여 \\(k\\)개 Cutoff를 적용하여 Precision을 구한다면, 이를 Precision@K라고 한다. Precision@K는 Cutoff에 따라 달라질 수 있다.\n\u0026nbsp\n Cutoff k=10인 경우 \\(\\rightarrow P(k=10) = 0.6\\)     순위 추천 아이템 정답 / 오답     1 엔진 오일 정답   2 자동차 배터리 정답   3 차량용 방향제 정답   4 자동차 장난감 오답   5 자동차 워셔액 정답   6 초보운전 스티커 오답   7 타이어 정답   8 자동차 보험 상품 오답   9 렌트카 이용권 오답   10 자동차 핸드폰 거치대 정답    \u0026nbsp\n Cutoff k=3인 경우 \\(\\rightarrow P(k=3) = 1\\)     순위 추천 아이템 정답 / 오답     1 엔진 오일 정답   2 자동차 배터리 정답   3 차량용 방향제 정답    \u0026nbsp\n Cutoff k=5인 경우 \\(\\rightarrow P(k=5) = 0.8\\)     순위 추천 아이템 정답 / 오답     1 엔진 오일 정답   2 자동차 배터리 정답   3 차량용 방향제 정답   4 자동차 장난감 오답   5 자동차 워셔액 정답    \u0026nbsp\n Cutoff k=7인 경우 \\(\\rightarrow P(k=7) = 0.714\\)     순위 추천 아이템 정답 / 오답     1 엔진 오일 정답   2 자동차 배터리 정답   3 차량용 방향제 정답   4 자동차 장난감 오답   5 자동차 워셔액 정답   6 초보운전 스티커 오답   7 타이어 정답    \u0026nbsp\nAverage Precision (AP@K) Cutoff가 \\(K\\)개인 Average Precision(AP@K)은 Precision@K의 평균을 구하는 과정이다.\n$$ AP@K = \\frac{1}{m} \\sum_{j=1}^K P(j) \\cdot rel(j) \\dots \\begin{cases} rel(j)=1 \u0026 \\text{if } j^{th} \\text{ item is relevant}, \\cr rel(j)=0 \u0026 \\text{if } j^{th} \\text{ item is not relevant}, \\cr \\end{cases} $$\n \\(K\\) : Cutoff 갯수 \\(m\\) : 추천 아이템 중 relevance가 있는 아이템의 갯수 (number of relevant document) \\(j\\) : 전체 추천 아이템 리스트 중, 해당 추천 아이템의 index \\(P(j)\\) : \\(j\\)번째 까지의 precision값 \\(rel(j)\\) : \\(j\\)번째의 relevance 여부  \u0026nbsp\n위에서 예시로 들었던 자동차용품 추천결과를 통해, [\\(AP@5\\), \\(AP@7\\), \\(AP@9\\), \\(AP@10\\)] 을 계산해 보았다. 특히 \\(AP@7\\) 와 \\(AP@9\\) 의 결과에서 관찰할 수 있듯이, \\(\\frac{1}{m}\\)에서 \\(m\\)은 relevance가 있는 경우만을 포함하기 때문에, 뒤에서 오답이 추가되어도 AP의 값이 페널티를 받지는 않는다.\n$$AP@5 = \\frac{1}{4} \\cdot \\left(\\frac{1}{1} + \\frac{2}{2} + \\frac{3}{3} + 0 + \\frac{4}{5}\\right) = 0.95$$\n$$AP@7 = \\frac{1}{5} \\cdot \\left(\\frac{1}{1} + \\frac{2}{2} + \\frac{3}{3} + 0 + \\frac{4}{5} + 0 + \\frac{5}{7} \\right) = 0.90$$\n$$AP@9 = \\frac{1}{5} \\cdot \\left(\\frac{1}{1} + \\frac{2}{2} + \\frac{3}{3} + 0 + \\frac{4}{5} + 0 + \\frac{5}{7} + 0 + 0 \\right) = 0.90$$\n$$AP@10 = \\frac{1}{6} \\cdot \\left(\\frac{1}{1} + \\frac{2}{2} + \\frac{3}{3} + 0 + \\frac{4}{5} + 0 + \\frac{5}{7} + 0 + 0 + \\frac{6}{10}\\right) = 0.85$$\n\u0026nbsp\n또한, 아래의 예시에서 Case A와 Case B를 비교해보면, 순위가 높은 추천 아이템이 정확할 수록 높은 AP값이 계산되므로, 추천의 순서 또는 순위가 평가 지표에 영향을 끼침을 알 수 있다.\n$$AP@5 = \\frac{1}{3} \\cdot \\left(\\frac{1}{1} + 0 + \\frac{2}{3} + 0 + \\frac{3}{5}\\right) = 0.75 \\dots \\text{(Case A)}$$\n$$AP@5 = \\frac{1}{3} \\cdot \\left(0 + \\frac{1}{2} + 0 + \\frac{2}{4} +\\frac{3}{5} \\right) = 0.53 \\dots \\text{(Case B)}$$\n\u0026nbsp\nMean Average Precision (MAP@K) AP는 각각의 사용자(또는 쿼리)에 대하여 계산한 것이므로, 각 사용자에 따라 AP값이 산출된다. Mean Average Precision(MAP)은 AP값들의 Mean을 구한 것으로, 식은 다음과 같다.\n$$MAP@K = \\frac{1}{U} \\sum_{u=1}^{U} (AP@K)_u$$\n \\(U\\) : 총 사용자의 수  \u0026nbsp \u0026nbsp\n마무리하며 이번 MAP에 대해 알아보았다. 다음 포스트에서는 역시나 추천시스템의 평가지표로 자주 등장하는 DCG(Discounted Cumulative Gain)에 대해서 공부하고 정리 할 예정이다.\nAP, MAP의 파이썬 코드로 된 구현체는 링크를 통해 참조할 수 있다.\n\u0026nbsp \u0026nbsp\nReference   https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision\n  http://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n  http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html\n  ","wordCount":"911","inLanguage":"en","datePublished":"2020-04-23T14:24:01+09:00","dateModified":"2020-04-23T14:24:01+09:00","author":{"@type":"Person","name":"Wyoung Seo"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lucaseo.github.io/posts/2020-04-23-mean-average-precision/"},"publisher":{"@type":"Organization","name":"WY Seo Blog","logo":{"@type":"ImageObject","url":"https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://lucaseo.github.io/ accesskey=h title="WY Seo Blog (Alt + H)">WY Seo Blog</a>
<span class=logo-switches><a id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://lucaseo.github.io/archives/ title=posts><span>posts</span></a></li><li><a href=https://lucaseo.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://lucaseo.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://lucaseo.github.io/about/ title=about><span>about</span></a></li><li><a href=https://lucaseo.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>[KR] 추천시스템의 평가 지표 : MAP</h1><div class=post-meta>April 23, 2020&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Wyoung Seo</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#%ec%b6%94%ec%b2%9c-%ec%8b%9c%ec%8a%a4%ed%85%9c%ec%9d%98-%ed%8f%89%ea%b0%80-%ec%a7%80%ed%91%9c-- aria-label="추천 시스템의 평가 지표 &amp;hellip; ?">추천 시스템의 평가 지표 &mldr; ?</a></li><li><a href=#precision--recall aria-label="Precision &amp;amp; Recall">Precision & Recall</a></li><li><a href=#%ec%b6%94%ec%b2%9c%ec%8b%9c%ec%8a%a4%ed%85%9c-%ea%b4%80%ec%a0%90%ec%97%90%ec%84%9c%ec%9d%98-precision--recall aria-label="추천시스템 관점에서의 Precision &amp;amp; Recall">추천시스템 관점에서의 Precision & Recall</a></li><li><a href=#cutoff-k aria-label="Cutoff (@K)">Cutoff (@K)</a></li><li><a href=#average-precision-apk aria-label="Average Precision (AP@K)">Average Precision (AP@K)</a></li><li><a href=#mean-average-precision-mapk aria-label="Mean Average Precision (MAP@K)">Mean Average Precision (MAP@K)</a></li><li><a href=#%eb%a7%88%eb%ac%b4%eb%a6%ac%ed%95%98%eb%a9%b0 aria-label=마무리하며>마무리하며</a></li><li><a href=#reference aria-label=Reference>Reference</a></li></ul></div></details></div><div class=post-content><h1 id=추천-시스템의-평가-지표-->추천 시스템의 평가 지표 &mldr; ?<a hidden class=anchor aria-hidden=true href=#추천-시스템의-평가-지표-->#</a></h1><p>추천 시스템은 이름에서도 알 수 있듯, 어떤 사용자가 관심을 가질 법한 아이템을 추천하는 알고리즘이다. 추천 시스템의 성능은 어떻게 평가할 수 있을까? 추천시스템에 대해 깊게 생각하지 않았을 적에는 분류 문제에서 성능을 평가하는 것과 비슷하다고 생각했다. <em>&ldquo;사용자가 관심을 가질만한 아이템이 맞다 또는 아니다."</em> 를 측정한다면, 우리에게 익숙한 precision, recall 등으로 생각해볼 수도 있을 것 같다.</p><p>하지만, 분류 성능 지표에서는 추천의 순서나 순위가 고려되지 않는다. (<del>역시 어줍잖게 생각하면 안 돼 &mldr;</del>)</p><p>추천 시스템을 통해 추천되는 아이템의 경우 추천의 정도가 동일하지 않다. 대부분의 추천 결과는 다음처럼 나올 수 있다고 생각해 볼 수 있다.</p><blockquote><p>1순위 : 가장 관심을 가질만한 것.<br>2순위 : 그 다음 차선책으로 관심을 가질만한 것.<br>3순위 : 그 다음으로 사용자가 관심을 가질만한 것.<br>4순위 : 또 그 다음 &mldr;
&mldr;</p></blockquote><p>&nbsp</p><p><strong>Mean Average Precision (MAP)</strong> 은 순서 또는 순위를 감안하는 부분을 반영하여 추천 시스템의 성능을 평가하는 지표로서, 과거 <strong><a href=https://www.kaggle.com/c/santander-product-recommendation/overview/evaluation>캐글의 Stander Product Recommendation</a></strong>, <strong><a href=https://arena.kakao.com/c/2>카카오아레나의 브런치 사용자를 위한 글 추천 대회</a></strong> 등 추천 시스템 관련 컴퍼티션에서 채점 방식으로 적용되었다. 특히 분류 문제에서 흔히 언급되는 Precision과 Recall이 적용된 성능평가 방법으로, 아주 낯설지는 않다.</p><p>&nbsp</p><h1 id=precision--recall>Precision & Recall<a hidden class=anchor aria-hidden=true href=#precision--recall>#</a></h1><table><thead><tr><th></th><th>Predict Positive</th><th>Predict Negative</th></tr></thead><tbody><tr><td>Actual Positive</td><td>True Positive</td><td>False Negative</td></tr><tr><td>Actual Negetave</td><td>False Positive</td><td>True Negative</td></tr></tbody></table><p>MAP에 대한 개념는 Precision과 Recall에서부터 시작한다. 일반적으로 위와과 같이 confusion matrix가 있다고 할 때, Precision과 Recall은 다음과 같다. (더 자세한 설명은 <a href=https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B0%80%EB%8F%84%EC%99%80_%EC%9E%AC%ED%98%84%EC%9C%A8>링크</a>를 참조하도록 하자)</p><p>$$\text{Precision} = \frac{\text{True Positive}}{\text{True Positive + False Positive}}$$</p><p>$$\text{Recall} = \frac{\text{True Positive}}{\text{True Positive + False Negative}}$$</p><p>&nbsp</p><h1 id=추천시스템-관점에서의-precision--recall>추천시스템 관점에서의 Precision & Recall<a hidden class=anchor aria-hidden=true href=#추천시스템-관점에서의-precision--recall>#</a></h1><p>추천시스템에서는 Precision과 Recall을 다음과 같이 해석할 수 있다. 추천시스템에서는 분자 부분을 <strong>relevant(관련있는)</strong> 라고 표현하기도 한다.</p><figure><center><img src=/2020-04-23-mean-average-precision/1.jpg></center></figure><ul><li><p>Precision 또는 \(P\):</p><ul><li>추천한 아이템 중, 실제로 사용자의 관심사와 겹치는 아이템의 비율</li><li>\(\text{Precision} = \frac{\text{Items from recommendation that fit user&rsquo;s interest}}{\text{Total items from recommendation}}\)</li></ul></li><li><p>Recall 또는 \(r\):</p><ul><li>실제로 사용자가 관심을 가진 아이템 중, 추천된 아이템이 겹치는 비율</li><li>\(\text{Recall} = \frac{\text{Items from recommendation that fit user&rsquo;s interest}}{\text{User&rsquo;s interest}}\)</li></ul></li></ul><p>&nbsp</p><h1 id=cutoff-k>Cutoff (@K)<a hidden class=anchor aria-hidden=true href=#cutoff-k>#</a></h1><p>MAP에서는 Cutoff의 개념이 등장한다. Cutoff는 &ldquo;잘라낸다"는 뜻으로, 쉽게 말하면 <strong>&ldquo;상위 K개만 고려하고 그 아래로는 쳐내기&rdquo;</strong> 라고 이해하면 된다. Cutoff를 가질 경우에는, <strong>@K</strong> 를 덧붙여서 표기한다.</p><p>어떠한 사용자의 기록을 통해서 자동차 용품와 관련된 아이템을 추천한 결과가 다음과 같다고 하자.</p><table><thead><tr><th>순위</th><th>추천 아이템</th><th>정답 / 오답</th></tr></thead><tbody><tr><td>1</td><td>엔진 오일</td><td>정답</td></tr><tr><td>2</td><td>자동차 배터리</td><td>정답</td></tr><tr><td>3</td><td>차량용 방향제</td><td>정답</td></tr><tr><td>4</td><td>자동차 장난감</td><td>오답</td></tr><tr><td>5</td><td>자동차 워셔액</td><td>정답</td></tr><tr><td>6</td><td>초보운전 스티커</td><td>오답</td></tr><tr><td>7</td><td>타이어</td><td>정답</td></tr><tr><td>8</td><td>운전자 보험 상품</td><td>오답</td></tr><tr><td>9</td><td>렌트카 이용권</td><td>오답</td></tr><tr><td>10</td><td>자동차 핸드폰 거치대</td><td>정답</td></tr></tbody></table><p>다음 예시의 추천시스템의 결과에 대하여 \(k\)개 Cutoff를 적용하여 Precision을 구한다면, 이를 <strong>Precision@K</strong>라고 한다. <strong>Precision@K</strong>는 Cutoff에 따라 달라질 수 있다.</p><p>&nbsp</p><ul><li>Cutoff k=10인 경우 \(\rightarrow P(k=10) = 0.6\)</li></ul><table><thead><tr><th>순위</th><th>추천 아이템</th><th>정답 / 오답</th></tr></thead><tbody><tr><td>1</td><td>엔진 오일</td><td>정답</td></tr><tr><td>2</td><td>자동차 배터리</td><td>정답</td></tr><tr><td>3</td><td>차량용 방향제</td><td>정답</td></tr><tr><td>4</td><td>자동차 장난감</td><td>오답</td></tr><tr><td>5</td><td>자동차 워셔액</td><td>정답</td></tr><tr><td>6</td><td>초보운전 스티커</td><td>오답</td></tr><tr><td>7</td><td>타이어</td><td>정답</td></tr><tr><td>8</td><td>자동차 보험 상품</td><td>오답</td></tr><tr><td>9</td><td>렌트카 이용권</td><td>오답</td></tr><tr><td>10</td><td>자동차 핸드폰 거치대</td><td>정답</td></tr></tbody></table><p>&nbsp</p><ul><li>Cutoff k=3인 경우 \(\rightarrow P(k=3) = 1\)</li></ul><table><thead><tr><th>순위</th><th>추천 아이템</th><th>정답 / 오답</th></tr></thead><tbody><tr><td>1</td><td>엔진 오일</td><td>정답</td></tr><tr><td>2</td><td>자동차 배터리</td><td>정답</td></tr><tr><td>3</td><td>차량용 방향제</td><td>정답</td></tr></tbody></table><p>&nbsp</p><ul><li>Cutoff k=5인 경우 \(\rightarrow P(k=5) = 0.8\)</li></ul><table><thead><tr><th>순위</th><th>추천 아이템</th><th>정답 / 오답</th></tr></thead><tbody><tr><td>1</td><td>엔진 오일</td><td>정답</td></tr><tr><td>2</td><td>자동차 배터리</td><td>정답</td></tr><tr><td>3</td><td>차량용 방향제</td><td>정답</td></tr><tr><td>4</td><td>자동차 장난감</td><td>오답</td></tr><tr><td>5</td><td>자동차 워셔액</td><td>정답</td></tr></tbody></table><p>&nbsp</p><ul><li>Cutoff k=7인 경우 \(\rightarrow P(k=7) = 0.714\)</li></ul><table><thead><tr><th>순위</th><th>추천 아이템</th><th>정답 / 오답</th></tr></thead><tbody><tr><td>1</td><td>엔진 오일</td><td>정답</td></tr><tr><td>2</td><td>자동차 배터리</td><td>정답</td></tr><tr><td>3</td><td>차량용 방향제</td><td>정답</td></tr><tr><td>4</td><td>자동차 장난감</td><td>오답</td></tr><tr><td>5</td><td>자동차 워셔액</td><td>정답</td></tr><tr><td>6</td><td>초보운전 스티커</td><td>오답</td></tr><tr><td>7</td><td>타이어</td><td>정답</td></tr></tbody></table><p>&nbsp</p><h1 id=average-precision-apk>Average Precision (AP@K)<a hidden class=anchor aria-hidden=true href=#average-precision-apk>#</a></h1><p>Cutoff가 \(K\)개인 Average Precision(AP@K)은 Precision@K의 평균을 구하는 과정이다.</p><p>$$
AP@K = \frac{1}{m} \sum_{j=1}^K P(j) \cdot rel(j) \dots \begin{cases}
rel(j)=1 & \text{if } j^{th} \text{ item is relevant}, \cr
rel(j)=0 & \text{if } j^{th} \text{ item is not relevant}, \cr
\end{cases}
$$</p><ul><li>\(K\) : Cutoff 갯수</li><li>\(m\) : 추천 아이템 중 relevance가 있는 아이템의 갯수 (number of relevant document)</li><li>\(j\) : 전체 추천 아이템 리스트 중, 해당 추천 아이템의 index</li><li>\(P(j)\) : \(j\)번째 까지의 precision값</li><li>\(rel(j)\) : \(j\)번째의 relevance 여부</li></ul><p>&nbsp</p><p>위에서 예시로 들었던 자동차용품 추천결과를 통해, [\(AP@5\), \(AP@7\), \(AP@9\), \(AP@10\)] 을 계산해 보았다. 특히 \(AP@7\) 와 \(AP@9\) 의 결과에서 관찰할 수 있듯이, \(\frac{1}{m}\)에서 \(m\)은 relevance가 있는 경우만을 포함하기 때문에, 뒤에서 오답이 추가되어도 AP의 값이 페널티를 받지는 않는다.</p><p>$$AP@5 = \frac{1}{4} \cdot \left(\frac{1}{1} + \frac{2}{2} + \frac{3}{3} + 0 + \frac{4}{5}\right) = 0.95$$</p><p>$$AP@7 = \frac{1}{5} \cdot \left(\frac{1}{1} + \frac{2}{2} + \frac{3}{3} + 0 + \frac{4}{5} + 0 + \frac{5}{7} \right) = 0.90$$</p><p>$$AP@9 = \frac{1}{5} \cdot \left(\frac{1}{1} + \frac{2}{2} + \frac{3}{3} + 0 + \frac{4}{5} + 0 + \frac{5}{7} + 0 + 0 \right) = 0.90$$</p><p>$$AP@10 = \frac{1}{6} \cdot \left(\frac{1}{1} + \frac{2}{2} + \frac{3}{3} + 0 + \frac{4}{5} + 0 + \frac{5}{7} + 0 + 0 + \frac{6}{10}\right) = 0.85$$</p><p>&nbsp</p><p>또한, 아래의 예시에서 Case A와 Case B를 비교해보면, 순위가 높은 추천 아이템이 정확할 수록 높은 AP값이 계산되므로, 추천의 순서 또는 순위가 평가 지표에 영향을 끼침을 알 수 있다.</p><p>$$AP@5 = \frac{1}{3} \cdot \left(\frac{1}{1} + 0 + \frac{2}{3} + 0 + \frac{3}{5}\right) = 0.75 \dots \text{(Case A)}$$</p><p>$$AP@5 = \frac{1}{3} \cdot \left(0 + \frac{1}{2} + 0 + \frac{2}{4} +\frac{3}{5} \right) = 0.53 \dots \text{(Case B)}$$</p><p>&nbsp</p><h1 id=mean-average-precision-mapk>Mean Average Precision (MAP@K)<a hidden class=anchor aria-hidden=true href=#mean-average-precision-mapk>#</a></h1><p>AP는 각각의 사용자(또는 쿼리)에 대하여 계산한 것이므로, 각 사용자에 따라 AP값이 산출된다. Mean Average Precision(MAP)은 AP값들의 Mean을 구한 것으로, 식은 다음과 같다.</p><p>$$MAP@K = \frac{1}{U} \sum_{u=1}^{U} (AP@K)_u$$</p><ul><li>\(U\) : 총 사용자의 수</li></ul><p>&nbsp
&nbsp</p><h1 id=마무리하며>마무리하며<a hidden class=anchor aria-hidden=true href=#마무리하며>#</a></h1><p>이번 MAP에 대해 알아보았다. 다음 포스트에서는 역시나 추천시스템의 평가지표로 자주 등장하는 DCG(Discounted Cumulative Gain)에 대해서 공부하고 정리 할 예정이다.</p><p>AP, MAP의 파이썬 코드로 된 구현체는 <a href=https://gist.github.com/bwhite/3726239>링크</a>를 통해 참조할 수 있다.</p><p>&nbsp
&nbsp</p><h1 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h1><ul><li><p><a href=https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision>https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision</a></p></li><li><p><a href=http://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf>http://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf</a></p></li><li><p><a href=http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html>http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html</a></p></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://lucaseo.github.io/tags/recsys/>recsys</a></li><li><a href=https://lucaseo.github.io/tags/map/>map</a></li></ul></footer></article></main><footer class=footer><span>© Wonyoung Seo 2021</span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>