<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[KR] ML/DL을 위한 소리 데이터 이해하기(3) - 파이썬으로 음악 데이터 읽어오기 | WY's Tech Blog</title><meta name=keywords content="audio processing,librosa,python,DSP"><meta name=description content="0. 데이터와 librosa 실제로 소리 데이터를 다뤄보기 위해서 음악 데이터를 준비하겠습니다. 음악 장르 분류 데이터셋으로 유명한 GTZAN Dataset을 다운받아 음악 파일을 하나 선택했습니다.
그리고 Librosa는 오디오와 음악 분석을 위 빠질 수 없는 파이썬 패키지입니다. 음원이나 소리 파일을 불러와 waveform을 시각화 하거나 다른 형태로 변환할 수 있는 기능을 제공합니다.
( Librosa는 pip install librosa 명령어를 통해 설치할 수 있습니다. )
import warnings warnings.filterwarnings(action='ignore') import numpy as np import matplotlib.pyplot as plt import IPython."><meta name=author content="Wonyoung Seo"><link rel=canonical href=https://lucaseo.github.io/posts/2021-01-22-hands-on-preprocess-audio-data/><meta name=google-site-verification content="XYZabc"><link href=/assets/css/stylesheet.min.d8cbf60331b9ced42909130bf88f8b97d2eb3de242444dcc9e2df410ceb098b9.css integrity="sha256-2Mv2AzG5ztQpCRML+I+Ll9LrPeJCRE3Mni30EM6wmLk=" rel="preload stylesheet" as=style><link rel=icon href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body);></script><meta property="og:title" content="[KR] ML/DL을 위한 소리 데이터 이해하기(3) - 파이썬으로 음악 데이터 읽어오기"><meta property="og:description" content="0. 데이터와 librosa 실제로 소리 데이터를 다뤄보기 위해서 음악 데이터를 준비하겠습니다. 음악 장르 분류 데이터셋으로 유명한 GTZAN Dataset을 다운받아 음악 파일을 하나 선택했습니다.
그리고 Librosa는 오디오와 음악 분석을 위 빠질 수 없는 파이썬 패키지입니다. 음원이나 소리 파일을 불러와 waveform을 시각화 하거나 다른 형태로 변환할 수 있는 기능을 제공합니다.
( Librosa는 pip install librosa 명령어를 통해 설치할 수 있습니다. )
import warnings warnings.filterwarnings(action='ignore') import numpy as np import matplotlib.pyplot as plt import IPython."><meta property="og:type" content="article"><meta property="og:url" content="https://lucaseo.github.io/posts/2021-01-22-hands-on-preprocess-audio-data/"><meta property="og:image" content="https://lucaseo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:published_time" content="2021-01-22T14:24:01+09:00"><meta property="article:modified_time" content="2021-01-22T14:24:01+09:00"><meta property="og:site_name" content="WY's Tech Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://lucaseo.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[KR] ML/DL을 위한 소리 데이터 이해하기(3) - 파이썬으로 음악 데이터 읽어오기"><meta name=twitter:description content="0. 데이터와 librosa 실제로 소리 데이터를 다뤄보기 위해서 음악 데이터를 준비하겠습니다. 음악 장르 분류 데이터셋으로 유명한 GTZAN Dataset을 다운받아 음악 파일을 하나 선택했습니다.
그리고 Librosa는 오디오와 음악 분석을 위 빠질 수 없는 파이썬 패키지입니다. 음원이나 소리 파일을 불러와 waveform을 시각화 하거나 다른 형태로 변환할 수 있는 기능을 제공합니다.
( Librosa는 pip install librosa 명령어를 통해 설치할 수 있습니다. )
import warnings warnings.filterwarnings(action='ignore') import numpy as np import matplotlib.pyplot as plt import IPython."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[KR] ML/DL을 위한 소리 데이터 이해하기(3) - 파이썬으로 음악 데이터 읽어오기","name":"[KR] ML\/DL을 위한 소리 데이터 이해하기(3) - 파이썬으로 음악 데이터 읽어오기","description":"0. 데이터와 librosa 실제로 소리 데이터를 다뤄보기 위해서 음악 데이터를 준비하겠습니다. 음악 장르 분류 데이터셋으로 유명한 GTZAN Dataset을 다운받아 음악 파일을 하나 선택했습니다.\n그리고 Librosa는 오디오와 음악 분석을 위 빠질 수 없는 파이썬 패키지입니다. …","keywords":["audio processing","librosa","python","DSP"],"articleBody":"0. 데이터와 librosa 실제로 소리 데이터를 다뤄보기 위해서 음악 데이터를 준비하겠습니다. 음악 장르 분류 데이터셋으로 유명한 GTZAN Dataset을 다운받아 음악 파일을 하나 선택했습니다.\n그리고 Librosa는 오디오와 음악 분석을 위 빠질 수 없는 파이썬 패키지입니다. 음원이나 소리 파일을 불러와 waveform을 시각화 하거나 다른 형태로 변환할 수 있는 기능을 제공합니다.\n( Librosa는 pip install librosa 명령어를 통해 설치할 수 있습니다. )\nimport warnings warnings.filterwarnings(action='ignore') import numpy as np import matplotlib.pyplot as plt import IPython.display as ipd import librosa import librosa.display file_path = 'disco.00054.wav' # 실습에 사용할 음악 파일 어떤 음악인지 한번 들어볼까요?\nipd.Audio(file_path)   1. Waveform 음원을 아래처럼 간단하게 읽어와보겠습니다. 튜플인 결과값에서 첫 번째는 numpy array형태의 waveform의 amplitude값이고, 두 번째 값은 sampling rate으로, 초당 샘플 갯수를 의미합니다. Sampling rate는 파일을 읽을 때, parameter로 설정할 수 있습니다. Default값은 22050입니다.\nwav, sr = librosa.load(file_path) print(\"Amplitude: \\n\", wav) print(\"Sampling rate: \", sr) Amplitude: [-0.08001709 -0.07550049 -0.08358765 ... 0.08270264 0.10083008 0.10562134] Sampling rate: 22050 시각화를 통해 데이터가 아래와 같은 형태의 waveform을 띄고 있음을 확인해 볼 수 있습니다.\nfig = plt.figure(figsize = (14,5)) librosa.display.waveplot(wav, sr=sr) plt.ylabel(\"Amplitude\") plt.show()    2. FFT (Fast Fourier Transform) 앞서 다룬 포스트에서 time-domain의 waveform을 FFT(Fast Fourier Transform)을 통해 분해(decompose)하고, frequency-domain으로 변환하여 원본 소리 데이터를 형성하는 주파수(frequency)의 정도를 파악하고 시각화 할 수 있다고 이해했습니다. 이번에는 numpy를 통해 앞서 구한 waveform amplitude에 FFT를 적용할 수 있습니다.\nFFT를 적용하여 시각화한 결과는 아래와 같습니다. 주로 1000Hz 이하로 많이 분포해 있는 것을 확인할 수 있네요.\nfft = np.fft.fft(wav) magnitude = np.abs(fft) frequency = np.linspace(0, sr, len(magnitude)) left_frequency = frequency[:int(len(frequency)/2)] left_magnitude = magnitude[:int(len(magnitude)/2)] fig = plt.figure(figsize = (14,5)) plt.plot(left_frequency, left_magnitude) plt.xlabel(\"Frequency\") plt.ylabel(\"Magnitude\") plt.show()    3. STFT (Short-Time Fourier Transform) STFT(Short-Time Fourier Transform)은 시간 정보가 유실되는 것을 방지하기 위해, 사전에 정의한 시간의 간격(window 또는 frame) 단위로 쪼개어 푸리에 변환을 적용하는 기법입니다. STFT는 librosa를 통해 적용할 수 있습니다. 이때, window의 크기(n_fft)와 window 간에 겹치는 사이즈(hop_length)를 설정해줍니다. 일반적으로는 n_fft의 1/4 정도가 겹치도록 설정한다고 합니다.\nn_fft = 2048 hop_length = 512 stft = librosa.stft(wav, n_fft = n_fft, hop_length = hop_length) spectrogram = np.abs(stft) print(\"Spectogram :\\n\", spectrogram) Spectogram : [[1.42030740e+00 7.47260690e-01 5.37097007e-02 ... 1.88164175e-01 1.21684396e+00 2.43966293e+00] [1.24079692e+00 6.81115210e-01 6.51928782e-02 ... 2.08189130e-01 1.22743416e+00 2.52433753e+00] [1.09137118e+00 4.82469022e-01 1.85490116e-01 ... 6.99194148e-02 1.43492615e+00 2.53518319e+00] ... [3.84226470e-04 1.63909295e-04 9.80101977e-05 ... 2.23124225e-04 2.80503096e-04 1.98973445e-04] [3.00532440e-04 1.77996873e-04 1.29194887e-04 ... 9.72686321e-05 2.01086092e-04 9.30428141e-05] [2.59254826e-04 9.42422412e-05 5.96536411e-05 ... 7.49909232e-05 1.41018099e-04 1.10232315e-04]] 3.1. Spectogram STFT를 적용하여 구한 spectogram을 아래와 같이 시각화 해봤습니다. x축은 시간, y축은 주파수, 그리고 주파수의 정도를 색깔로 확인할 수 있습니다. 그런데 값이 너무 미세해서 차이를 파악하고 관찰하기 적합하지 않습니다.\nfig = plt.figure(figsize = (14,5)) librosa.display.specshow(spectrogram, sr=sr, hop_length=hop_length) plt.xlabel(\"Time\") plt.ylabel(\"Frequency\") plt.plasma() plt.show()    3.2. Log-spectogram 그래서 보통 푸리에변환 이후 dB(데시벨) scaling을 적용한 Log-spectogram을 구합니다. 다분히 시각적인 이유뿐만 아니라, 사람의 청각 또한 소리를 dB scale 로 인식하기 때문에, 이를 반영하여 spectogram을 나타내는 것이 분석에 용이합니다.\nlibrosa.amplitude_to_db()를 통해 Log-spectogram을 구하여 시각화 한 결과입니다. 대부분의 에너지가 1024Hz이하의 낮은 주파수대역에 모여 있는 것을 볼 수 있네요.\nlog_spectrogram = librosa.amplitude_to_db(spectrogram) fig = plt.figure(figsize = (14,5)) librosa.display.specshow(log_spectrogram, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log') plt.xlabel(\"Time\") plt.ylabel(\"Frequency\") plt.colorbar(format='%+2.0fdB') plt.show()    4. MFCC 마지막으로 MFCC(Mel Frequency Cepstral Coefficient)를 구하고 시각화해보겠습니다. MFCC는 오디오 신호 처리 분야에서 많이 사용되는 소리 데이터의 특징값(Feature)으로, 사람의 청각이 예민하게 반응하는 정보를 강조하여 소리가 가지는 고유한 특징을 추출한 값입니다.\n마찬가지로 librosa.feature.mfcc()를 통해 feature값을 아래와 같이 추출할 수 있습니다. 파라미터 중 n_mfcc는 추출하고자 하는 mfcc의 개수입니다. 이번 실습에서는 13개로 설정했습니다.\nMFCCs = librosa.feature.mfcc(wav, sr = 22050, n_fft = n_fft, hop_length = hop_length, n_mfcc = 13) # number of coefficient we want to extract print(\"MFCCs Shape: \", MFCCs.shape) print(\"MFCCs: \\n\", MFCCs) MFCCs Shape: (13, 1293) MFCCs: [[-176.91516 -173.07141 -171.01598 ... -144.9992 -153.77185 -155.61522 ] [ 118.94415 117.39079 108.01162 ... 111.50748 108.44453 113.359665 ] [ -12.249197 -16.364796 -20.116379 ... -68.0366 -40.615326 -32.124104 ] ... [ -7.0000467 -8.825797 -10.732431 ... -16.528994 -17.69807 -21.954914 ] [ 10.861979 10.393564 7.8947186 ... -8.206779 -3.6493917 -4.4267316] [ -12.490692 -10.728968 -14.610505 ... -2.9667187 -12.053108 -9.9868355]] fig = plt.figure(figsize = (14,5)) librosa.display.specshow(MFCCs, sr=sr, hop_length=hop_length, x_axis='time',) plt.xlabel(\"Time\") plt.ylabel(\"Frequency\") plt.colorbar(format='%+2.0fdB') plt.show()    5. 한줄 요약  Librosa라는 킹갓제너럴 파이썬 패키지를 이용해서 소리 데이터를 불러오고, 변형할 수 있다!  6. Reference  audio-processing-wave by scpark20  ","wordCount":"643","inLanguage":"en","datePublished":"2021-01-22T14:24:01+09:00","dateModified":"2021-01-22T14:24:01+09:00","author":{"@type":"Person","name":"Wonyoung Seo"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lucaseo.github.io/posts/2021-01-22-hands-on-preprocess-audio-data/"},"publisher":{"@type":"Organization","name":"WY's Tech Blog","logo":{"@type":"ImageObject","url":"https://lucaseo.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://lucaseo.github.io/ accesskey=h title="Tech Blog (Alt + H)">Tech Blog</a>
<span class=logo-switches><a id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://lucaseo.github.io/archives/ title=posts><span>posts</span></a></li><li><a href=https://lucaseo.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://lucaseo.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://lucaseo.github.io/about/ title=about><span>about</span></a></li><li><a href=https://lucaseo.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>[KR] ML/DL을 위한 소리 데이터 이해하기(3) - 파이썬으로 음악 데이터 읽어오기</h1><div class=post-meta>January 22, 2021&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Wonyoung Seo</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#0-%eb%8d%b0%ec%9d%b4%ed%84%b0%ec%99%80-librosa aria-label="0. 데이터와 librosa">0. 데이터와 <code>librosa</code></a></li><li><a href=#1-waveform aria-label="1. Waveform">1. Waveform</a></li><li><a href=#2-fft-fast-fourier-transform aria-label="2. FFT (Fast Fourier Transform)">2. FFT (Fast Fourier Transform)</a></li><li><a href=#3-stft-short-time-fourier-transform aria-label="3. STFT (Short-Time Fourier Transform)">3. STFT (Short-Time Fourier Transform)</a><ul><li><a href=#31-spectogram aria-label="3.1. Spectogram">3.1. Spectogram</a></li><li><a href=#32-log-spectogram aria-label="3.2. Log-spectogram">3.2. Log-spectogram</a></li></ul></li><li><a href=#4-mfcc aria-label="4. MFCC">4. MFCC</a></li><li><a href=#5-%ed%95%9c%ec%a4%84-%ec%9a%94%ec%95%bd aria-label="5. 한줄 요약">5. 한줄 요약</a></li><li><a href=#6-reference aria-label="6. Reference">6. Reference</a></li></ul></div></details></div><div class=post-content><h2 id=0-데이터와-librosa>0. 데이터와 <code>librosa</code><a hidden class=anchor aria-hidden=true href=#0-데이터와-librosa>#</a></h2><p>실제로 소리 데이터를 다뤄보기 위해서 음악 데이터를 준비하겠습니다. 음악 장르 분류 데이터셋으로 유명한 <a href=https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification target=_blank>GTZAN Dataset</a>을 다운받아 음악 파일을 하나 선택했습니다.</p><p>그리고 <a href=https://librosa.org/doc/latest/index.html target=_blank>Librosa</a>는 오디오와 음악 분석을 위 빠질 수 없는 파이썬 패키지입니다. 음원이나 소리 파일을 불러와 waveform을 시각화 하거나 다른 형태로 변환할 수 있는 기능을 제공합니다.</p><p>( Librosa는 <code>pip install librosa</code> 명령어를 통해 설치할 수 있습니다. )</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> warnings
warnings<span style=color:#f92672>.</span>filterwarnings(action<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ignore&#39;</span>)

<span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
<span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#f92672>as</span> plt
<span style=color:#f92672>import</span> IPython.display <span style=color:#f92672>as</span> ipd

<span style=color:#f92672>import</span> librosa
<span style=color:#f92672>import</span> librosa.display

file_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;disco.00054.wav&#39;</span> <span style=color:#75715e># 실습에 사용할 음악 파일</span>
</code></pre></div><p>어떤 음악인지 한번 들어볼까요?</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>ipd<span style=color:#f92672>.</span>Audio(file_path)
</code></pre></div><figure><audio controls preload=metadata>
<source src=/2021-01-22-hands-on-preprocess-audio-data/disco.00054.wav type=audio/mpeg></audio></figure><h2 id=1-waveform>1. Waveform<a hidden class=anchor aria-hidden=true href=#1-waveform>#</a></h2><p>음원을 아래처럼 간단하게 읽어와보겠습니다. 튜플인 결과값에서 첫 번째는 numpy array형태의 waveform의 amplitude값이고, 두 번째 값은 sampling rate으로, 초당 샘플 갯수를 의미합니다. Sampling rate는 파일을 읽을 때, parameter로 설정할 수 있습니다. Default값은 22050입니다.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>wav, sr <span style=color:#f92672>=</span> librosa<span style=color:#f92672>.</span>load(file_path)

<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Amplitude: </span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, wav)
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Sampling rate: &#34;</span>, sr)
</code></pre></div><pre><code class=language-pure_text data-lang=pure_text>    Amplitude: 
     [-0.08001709 -0.07550049 -0.08358765 ...  0.08270264  0.10083008
      0.10562134]
    Sampling rate:  22050
</code></pre><p>시각화를 통해 데이터가 아래와 같은 형태의 waveform을 띄고 있음을 확인해 볼 수 있습니다.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>14</span>,<span style=color:#ae81ff>5</span>))
librosa<span style=color:#f92672>.</span>display<span style=color:#f92672>.</span>waveplot(wav, sr<span style=color:#f92672>=</span>sr)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Amplitude&#34;</span>)
plt<span style=color:#f92672>.</span>show()
</code></pre></div><figure><center><img src=/2021-01-22-hands-on-preprocess-audio-data/output_8_0.png></center></figure><h2 id=2-fft-fast-fourier-transform>2. FFT (Fast Fourier Transform)<a hidden class=anchor aria-hidden=true href=#2-fft-fast-fourier-transform>#</a></h2><p>앞서 다룬 포스트에서 time-domain의 waveform을 FFT(Fast Fourier Transform)을 통해 분해(decompose)하고, frequency-domain으로 변환하여 원본 소리 데이터를 형성하는 주파수(frequency)의 정도를 파악하고 시각화 할 수 있다고 이해했습니다. 이번에는 numpy를 통해 앞서 구한 waveform amplitude에 FFT를 적용할 수 있습니다.</p><p>FFT를 적용하여 시각화한 결과는 아래와 같습니다. 주로 1000Hz 이하로 많이 분포해 있는 것을 확인할 수 있네요.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fft <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>fft<span style=color:#f92672>.</span>fft(wav) 

magnitude <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>abs(fft)
frequency <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0</span>, sr, len(magnitude))

left_frequency <span style=color:#f92672>=</span> frequency[:int(len(frequency)<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>)]
left_magnitude <span style=color:#f92672>=</span> magnitude[:int(len(magnitude)<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>)]

fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>14</span>,<span style=color:#ae81ff>5</span>))
plt<span style=color:#f92672>.</span>plot(left_frequency, left_magnitude)
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Frequency&#34;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Magnitude&#34;</span>)
plt<span style=color:#f92672>.</span>show()
</code></pre></div><figure><center><img src=/2021-01-22-hands-on-preprocess-audio-data/output_10_0.png></center></figure><h2 id=3-stft-short-time-fourier-transform>3. STFT (Short-Time Fourier Transform)<a hidden class=anchor aria-hidden=true href=#3-stft-short-time-fourier-transform>#</a></h2><p>STFT(Short-Time Fourier Transform)은 시간 정보가 유실되는 것을 방지하기 위해, 사전에 정의한 시간의 간격(window 또는 frame) 단위로 쪼개어 푸리에 변환을 적용하는 기법입니다. STFT는 <strong>librosa</strong>를 통해 적용할 수 있습니다. 이때, window의 크기(<code>n_fft</code>)와 window 간에 겹치는 사이즈(<code>hop_length</code>)를 설정해줍니다. 일반적으로는 <code>n_fft</code>의 1/4 정도가 겹치도록 설정한다고 합니다.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>n_fft <span style=color:#f92672>=</span> <span style=color:#ae81ff>2048</span> 
hop_length <span style=color:#f92672>=</span> <span style=color:#ae81ff>512</span> 

stft <span style=color:#f92672>=</span> librosa<span style=color:#f92672>.</span>stft(wav, n_fft <span style=color:#f92672>=</span> n_fft, hop_length <span style=color:#f92672>=</span> hop_length)
spectrogram <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>abs(stft)
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Spectogram :</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, spectrogram)
</code></pre></div><pre><code class=language-pure_text data-lang=pure_text>    Spectogram :
     [[1.42030740e+00 7.47260690e-01 5.37097007e-02 ... 1.88164175e-01
      1.21684396e+00 2.43966293e+00]
     [1.24079692e+00 6.81115210e-01 6.51928782e-02 ... 2.08189130e-01
      1.22743416e+00 2.52433753e+00]
     [1.09137118e+00 4.82469022e-01 1.85490116e-01 ... 6.99194148e-02
      1.43492615e+00 2.53518319e+00]
     ...
     [3.84226470e-04 1.63909295e-04 9.80101977e-05 ... 2.23124225e-04
      2.80503096e-04 1.98973445e-04]
     [3.00532440e-04 1.77996873e-04 1.29194887e-04 ... 9.72686321e-05
      2.01086092e-04 9.30428141e-05]
     [2.59254826e-04 9.42422412e-05 5.96536411e-05 ... 7.49909232e-05
      1.41018099e-04 1.10232315e-04]]
</code></pre><h3 id=31-spectogram>3.1. Spectogram<a hidden class=anchor aria-hidden=true href=#31-spectogram>#</a></h3><p>STFT를 적용하여 구한 spectogram을 아래와 같이 시각화 해봤습니다. x축은 시간, y축은 주파수, 그리고 주파수의 정도를 색깔로 확인할 수 있습니다. 그런데 값이 너무 미세해서 차이를 파악하고 관찰하기 적합하지 않습니다.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>14</span>,<span style=color:#ae81ff>5</span>))
librosa<span style=color:#f92672>.</span>display<span style=color:#f92672>.</span>specshow(spectrogram, sr<span style=color:#f92672>=</span>sr, hop_length<span style=color:#f92672>=</span>hop_length)
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Time&#34;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Frequency&#34;</span>)
plt<span style=color:#f92672>.</span>plasma()
plt<span style=color:#f92672>.</span>show()
</code></pre></div><figure><center><img src=/2021-01-22-hands-on-preprocess-audio-data/output_14_0.png></center></figure><h3 id=32-log-spectogram>3.2. Log-spectogram<a hidden class=anchor aria-hidden=true href=#32-log-spectogram>#</a></h3><p>그래서 보통 푸리에변환 이후 dB(데시벨) scaling을 적용한 Log-spectogram을 구합니다. 다분히 시각적인 이유뿐만 아니라, 사람의 청각 또한 소리를 dB scale 로 인식하기 때문에, 이를 반영하여 spectogram을 나타내는 것이 분석에 용이합니다.</p><p><code>librosa.amplitude_to_db()</code>를 통해 Log-spectogram을 구하여 시각화 한 결과입니다. 대부분의 에너지가 1024Hz이하의 낮은 주파수대역에 모여 있는 것을 볼 수 있네요.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>log_spectrogram <span style=color:#f92672>=</span> librosa<span style=color:#f92672>.</span>amplitude_to_db(spectrogram)

fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>14</span>,<span style=color:#ae81ff>5</span>))
librosa<span style=color:#f92672>.</span>display<span style=color:#f92672>.</span>specshow(log_spectrogram, 
                         sr<span style=color:#f92672>=</span>sr, 
                         hop_length<span style=color:#f92672>=</span>hop_length,
                         x_axis<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;time&#39;</span>,
                         y_axis<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;log&#39;</span>)
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Time&#34;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Frequency&#34;</span>)
plt<span style=color:#f92672>.</span>colorbar(format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%+2.0f</span><span style=color:#e6db74> dB&#39;</span>)
plt<span style=color:#f92672>.</span>show()
</code></pre></div><figure><center><img src=/2021-01-22-hands-on-preprocess-audio-data/output_16_0.png></center></figure><h2 id=4-mfcc>4. MFCC<a hidden class=anchor aria-hidden=true href=#4-mfcc>#</a></h2><p>마지막으로 MFCC(Mel Frequency Cepstral Coefficient)를 구하고 시각화해보겠습니다. MFCC는 오디오 신호 처리 분야에서 많이 사용되는 소리 데이터의 특징값(Feature)으로, 사람의 청각이 예민하게 반응하는 정보를 강조하여 소리가 가지는 고유한 특징을 추출한 값입니다.</p><p>마찬가지로 <code>librosa.feature.mfcc()</code>를 통해 feature값을 아래와 같이 추출할 수 있습니다. 파라미터 중 <code>n_mfcc</code>는 추출하고자 하는 mfcc의 개수입니다. 이번 실습에서는 13개로 설정했습니다.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>MFCCs <span style=color:#f92672>=</span> librosa<span style=color:#f92672>.</span>feature<span style=color:#f92672>.</span>mfcc(wav, 
                             sr <span style=color:#f92672>=</span> <span style=color:#ae81ff>22050</span>,
                             n_fft <span style=color:#f92672>=</span> n_fft,
                             hop_length <span style=color:#f92672>=</span> hop_length,
                             n_mfcc <span style=color:#f92672>=</span> <span style=color:#ae81ff>13</span>)   <span style=color:#75715e># number of coefficient we want to extract</span>
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;MFCCs Shape: &#34;</span>, MFCCs<span style=color:#f92672>.</span>shape)
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;MFCCs: </span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, MFCCs)
</code></pre></div><pre><code class=language-pure_text data-lang=pure_text>    MFCCs Shape:  (13, 1293)
    MFCCs: 
     [[-176.91516   -173.07141   -171.01598   ... -144.9992    -153.77185
      -155.61522  ]
     [ 118.94415    117.39079    108.01162   ...  111.50748    108.44453
       113.359665 ]
     [ -12.249197   -16.364796   -20.116379  ...  -68.0366     -40.615326
       -32.124104 ]
     ...
     [  -7.0000467   -8.825797   -10.732431  ...  -16.528994   -17.69807
       -21.954914 ]
     [  10.861979    10.393564     7.8947186 ...   -8.206779    -3.6493917
        -4.4267316]
     [ -12.490692   -10.728968   -14.610505  ...   -2.9667187  -12.053108
        -9.9868355]]
</code></pre><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize <span style=color:#f92672>=</span> (<span style=color:#ae81ff>14</span>,<span style=color:#ae81ff>5</span>))
librosa<span style=color:#f92672>.</span>display<span style=color:#f92672>.</span>specshow(MFCCs, 
                         sr<span style=color:#f92672>=</span>sr, 
                         hop_length<span style=color:#f92672>=</span>hop_length,
                         x_axis<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;time&#39;</span>,)
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Time&#34;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Frequency&#34;</span>)
plt<span style=color:#f92672>.</span>colorbar(format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%+2.0f</span><span style=color:#e6db74> dB&#39;</span>)
plt<span style=color:#f92672>.</span>show()
</code></pre></div><figure><center><img src=/2021-01-22-hands-on-preprocess-audio-data/output_20_0.png></center></figure><h2 id=5-한줄-요약>5. 한줄 요약<a hidden class=anchor aria-hidden=true href=#5-한줄-요약>#</a></h2><ul><li><strong>Librosa</strong>라는 <del>킹갓제너럴</del> 파이썬 패키지를 이용해서 소리 데이터를 불러오고, 변형할 수 있다!</li></ul><h2 id=6-reference>6. Reference<a hidden class=anchor aria-hidden=true href=#6-reference>#</a></h2><ul><li><a href=https://github.com/scpark20/audio-preprocessing-practice/blob/master/audio-processing-wave.ipynb target=_blank>audio-processing-wave by scpark20</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://lucaseo.github.io/tags/audio-processing/>audio processing</a></li><li><a href=https://lucaseo.github.io/tags/librosa/>librosa</a></li><li><a href=https://lucaseo.github.io/tags/python/>python</a></li><li><a href=https://lucaseo.github.io/tags/dsp/>DSP</a></li></ul></footer></article></main><footer class=footer><span>© Wonyoung Seo 2021</span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>